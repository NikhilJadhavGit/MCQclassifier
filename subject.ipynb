{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "subject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRKCNqGaQ7pP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngoP30apREmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "science='science.json'\n",
        "history='history.json'\n",
        "geography='geography.json'\n",
        "book='book.json'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-qACmglRGNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "science_questions=json.load(open(science,'r'))\n",
        "history_questions=json.load(open(history,'r'))\n",
        "geography_questions=json.load(open(geography,'r'))\n",
        "book_questions=json.load(open(book,'r'))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpUggr3_RIuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=[]\n",
        "Y=[]\n",
        "answer=[]\n",
        "for i in science_questions:\n",
        "    X.append(str(i[0]))\n",
        "    Y.append(int(i[1]))\n",
        "for i in geography_questions:\n",
        "    X.append(str(i[0]))\n",
        "    Y.append(int(i[1]))\n",
        "for i in history_questions:\n",
        "    X.append(str(i[0]))\n",
        "    Y.append(int(i[1]))\n",
        "for i in book_questions:\n",
        "    answer.append(str(i['question']))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDVwJS3qU4MB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "for i in range(len(answer)):\n",
        "  answer[i]=(re.sub(r'Q[0-9]+.','',answer[i]))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFyMfW7XRI0h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e62f1af1-3ab7-4909-c111-86c76bdbdeac"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#Tokenize the sentences\n",
        "tokenizer = Tokenizer(oov_token='$')\n",
        "\n",
        "#preparing vocabulary\n",
        "tokenizer.fit_on_texts(answer)\n",
        "\n",
        "#converting text into integer sequences\n",
        "x_tr_seq  = tokenizer.texts_to_sequences(X) \n",
        "ans_text_seq=tokenizer.texts_to_sequences(answer)\n",
        "#padding to prepare sequences of same length\n",
        "x_tr_seq  = pad_sequences(x_tr_seq, maxlen=100,dtype='float32')\n",
        "ans_text_seq = pad_sequences(ans_text_seq, maxlen=100,dtype='float32')\n",
        "y_tr_seq=to_categorical(Y,3)\n",
        "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
        "print(size_of_vocabulary)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qneZOLviRI3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x_tr_seq, y_tr_seq, test_size=0.33, random_state=42)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VhpCUXaRI6I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "cccb47cc-2479-4e22-bead-e43d2a723d00"
      },
      "source": [
        "from tensorflow.python.keras.models import *\n",
        "from tensorflow.python.keras.layers import *\n",
        "from tensorflow.python.keras.callbacks import *\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "#embedding layer\n",
        "model.add(Embedding(size_of_vocabulary,300,input_length=100,trainable=True)) \n",
        "\n",
        "#lstm layer\n",
        "model.add(LSTM(128,return_sequences=True,dropout=0.2))\n",
        "\n",
        "#Global Maxpooling\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "#Dense Layer\n",
        "model.add(Dense(64,activation='relu')) \n",
        "model.add(Dense(3,activation='softmax')) \n",
        "\n",
        "#Add loss function, metrics, optimizer\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=[\"acc\"]) \n",
        "\n",
        "#Adding callbacks\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
        "mc=ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
        "\n",
        "#Print summary of model\n",
        "print(model.summary())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 300)          1647000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100, 128)          219648    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 1,875,099\n",
            "Trainable params: 1,875,099\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq0mbRxNRI9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "d4b52a3a-bc1c-41fc-ae69-8ca3bcdd5015"
      },
      "source": [
        "history = model.fit(X_train,y_train,epochs=20,steps_per_epoch=300,validation_data=(X_test,y_test),verbose=1,callbacks=[es,mc])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.9797 - acc: 0.5517\n",
            "Epoch 00001: val_acc improved from -inf to 0.58491, saving model to best_model.h5\n",
            "300/300 [==============================] - 29s 97ms/step - loss: 0.9797 - acc: 0.5517 - val_loss: 0.9554 - val_acc: 0.5849\n",
            "Epoch 2/20\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.9754 - acc: 0.5483\n",
            "Epoch 00002: val_acc did not improve from 0.58491\n",
            "300/300 [==============================] - 29s 96ms/step - loss: 0.9754 - acc: 0.5483 - val_loss: 0.9563 - val_acc: 0.5849\n",
            "Epoch 3/20\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.9666 - acc: 0.5483\n",
            "Epoch 00003: val_acc did not improve from 0.58491\n",
            "300/300 [==============================] - 29s 95ms/step - loss: 0.9666 - acc: 0.5483 - val_loss: 0.9668 - val_acc: 0.5849\n",
            "Epoch 4/20\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.9490 - acc: 0.5650\n",
            "Epoch 00004: val_acc did not improve from 0.58491\n",
            "300/300 [==============================] - 29s 95ms/step - loss: 0.9490 - acc: 0.5650 - val_loss: 0.9508 - val_acc: 0.5849\n",
            "Epoch 5/20\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.9438 - acc: 0.5617\n",
            "Epoch 00005: val_acc did not improve from 0.58491\n",
            "300/300 [==============================] - 31s 102ms/step - loss: 0.9438 - acc: 0.5617 - val_loss: 0.9548 - val_acc: 0.5849\n",
            "Epoch 6/20\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.9629 - acc: 0.5417\n",
            "Epoch 00006: val_acc did not improve from 0.58491\n",
            "300/300 [==============================] - 31s 102ms/step - loss: 0.9629 - acc: 0.5417 - val_loss: 0.9589 - val_acc: 0.5849\n",
            "Epoch 7/20\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.9321 - acc: 0.5650\n",
            "Epoch 00007: val_acc improved from 0.58491 to 0.59119, saving model to best_model.h5\n",
            "300/300 [==============================] - 31s 104ms/step - loss: 0.9321 - acc: 0.5650 - val_loss: 0.9258 - val_acc: 0.5912\n",
            "Epoch 8/20\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.9170 - acc: 0.5683\n",
            "Epoch 00008: val_acc improved from 0.59119 to 0.59748, saving model to best_model.h5\n",
            "300/300 [==============================] - 29s 98ms/step - loss: 0.9170 - acc: 0.5683 - val_loss: 0.9120 - val_acc: 0.5975\n",
            "Epoch 9/20\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.9150 - acc: 0.5900\n",
            "Epoch 00009: val_acc improved from 0.59748 to 0.60377, saving model to best_model.h5\n",
            "300/300 [==============================] - 30s 99ms/step - loss: 0.9150 - acc: 0.5900 - val_loss: 0.8945 - val_acc: 0.6038\n",
            "Epoch 10/20\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.8752 - acc: 0.6067\n",
            "Epoch 00010: val_acc improved from 0.60377 to 0.61635, saving model to best_model.h5\n",
            "300/300 [==============================] - 32s 105ms/step - loss: 0.8752 - acc: 0.6067 - val_loss: 0.8791 - val_acc: 0.6164\n",
            "Epoch 11/20\n",
            "220/300 [=====================>........] - ETA: 8s - loss: 0.8582 - acc: 0.6364WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 6000 batches). You may need to use the repeat() function when building your dataset.\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.61635\n",
            "220/300 [=====================>........] - 23s 105ms/step - loss: 0.8582 - acc: 0.6364 - val_loss: 0.8761 - val_acc: 0.5975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMvhvKfEXBHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res=model.predict(ans_text_seq)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1IGgs2wYvAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre(result):\n",
        "  mapper={0:'science',1:'history',2:'geography'}\n",
        "  result=list(result)\n",
        "  return mapper[result.index(max(result))]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVWBLBJqZHUt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "890cc6cc-999d-4718-9934-c1bfd7c7a738"
      },
      "source": [
        "pre(res[2])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'geography'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN9H_tDBRJAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(res)):\n",
        "  book_questions[i]['class']=pre(res[i])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGrXS4kRRJDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"subject.json\",'w') as file: \n",
        "  json.dump(book_questions,file,indent=4)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMyVvnaCRJGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQfDA3FnRJJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}